{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0ffhSZJE_AO"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# üìå Install Necessary Libraries (Run in Colab)\n",
        "try:\n",
        "    !pip install torch torchvision torchaudio transformers datasets sentencepiece gradio torch_xla nest_asyncio shap optuna nltk wordcloud tqdm aiohttp flask ray[serve] tensorflow tensorflow-datasets tensorflow-addons psutil beautifulsoup4 requests --quiet\n",
        "except Exception as e:\n",
        "    print(f\"Error installing libraries: {e}\")\n",
        "\n",
        "# ==============================\n",
        "# üß† Core Imports\n",
        "# ==============================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel, AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow as tf\n",
        "import gradio as gr\n",
        "import ray\n",
        "from ray import tune\n",
        "import optuna\n",
        "import shap\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from wordcloud import WordCloud\n",
        "import joblib\n",
        "import asyncio\n",
        "import aiohttp\n",
        "from flask import Flask, jsonify\n",
        "import nest_asyncio\n",
        "import psutil\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from scipy import spatial\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.tokenize import word_tokenize\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "nest_asyncio.apply()\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==============================\n",
        "# ‚ö° GPU Configuration\n",
        "# ==============================\n",
        "def configure_gpu():\n",
        "    \"\"\"Detect and configure the best available device for Colab\"\"\"\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda\")\n",
        "            print(f\"üéÆ GPU Found: {torch.cuda.get_device_name(0)}\")\n",
        "        elif 'XLA_USE_BF16' in os.environ:  # Better TPU detection\n",
        "            import torch_xla.core.xla_model as xm\n",
        "            device = xm.xla_device()\n",
        "            print(\"üöÄ TPU Detected\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            print(\"üñ•Ô∏è Using CPU\")\n",
        "            torch.set_num_threads(os.cpu_count())\n",
        "\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        return device\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring GPU: {e}\")\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "DEVICE = configure_gpu()\n",
        "\n",
        "# ==============================\n",
        "# üé• Create Movie Dataset\n",
        "# ==============================\n",
        "class MovieDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size=50000):\n",
        "        try:\n",
        "            # Make sure data is properly aligned\n",
        "            self.size = size\n",
        "            num_copies = (size // 5) + 1\n",
        "            self.movies = [\"Inception\", \"Avatar\", \"Titanic\", \"Interstellar\", \"Joker\"] * num_copies\n",
        "            self.genres = [\"Sci-Fi\", \"Action\", \"Drama\", \"Thriller\", \"Fantasy\"] * num_copies\n",
        "            self.emotions = [\"Excited\", \"Happy\", \"Sad\", \"Adventurous\", \"Nostalgic\"] * num_copies\n",
        "            self.ratings = np.random.uniform(6.5, 9.5, size)\n",
        "            self.watch_times = [\"Morning\", \"Evening\", \"Night\"] * ((size // 3) + 1)\n",
        "            self.platforms = [\"Netflix\", \"Amazon Prime\", \"Disney+\"] * ((size // 3) + 1)\n",
        "\n",
        "            # Truncate all lists to exactly size\n",
        "            self.movies = self.movies[:size]\n",
        "            self.genres = self.genres[:size]\n",
        "            self.emotions = self.emotions[:size]\n",
        "            self.watch_times = self.watch_times[:size]\n",
        "            self.platforms = self.platforms[:size]\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating movie dataset: {e}\")\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            if idx >= self.size:\n",
        "                raise IndexError(f\"Index {idx} out of bounds for dataset of size {self.size}\")\n",
        "\n",
        "            return {\n",
        "                'features': torch.tensor([\n",
        "                    idx % 50,\n",
        "                    self.ratings[idx],\n",
        "                    len(self.movies[idx]) / 10\n",
        "                ], dtype=torch.float32),\n",
        "                'target': torch.tensor(1 if self.ratings[idx] > 7.5 else 0, dtype=torch.long)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting item from dataset: {e}\")\n",
        "            raise\n",
        "\n",
        "# ==============================\n",
        "# üåå AI-Powered Movie Recommendation Model\n",
        "# ==============================\n",
        "class MovieAI(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "        self.dropout = nn.Dropout(0.2)  # Add dropout for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "# ==============================\n",
        "# üöÄ GPU Accelerated Training\n",
        "# ==============================\n",
        "def train_model():\n",
        "    try:\n",
        "        dataset = MovieDataset(size=50000)\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "        model = MovieAI().to(DEVICE)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Add early stopping\n",
        "        best_loss = float('inf')\n",
        "        patience = 3\n",
        "        counter = 0\n",
        "\n",
        "        for epoch in range(5):\n",
        "            model.train()\n",
        "            epoch_loss = 0\n",
        "            for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\", leave=False):\n",
        "                features = batch['features'].to(DEVICE)\n",
        "                targets = batch['target'].to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                predictions = model(features)\n",
        "                loss = loss_fn(predictions, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            avg_loss = epoch_loss / len(dataloader)\n",
        "            print(f\"üéØ Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Early stopping logic\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                counter = 0\n",
        "                torch.save(model.state_dict(), \"best_model.pt\")\n",
        "            else:\n",
        "                counter += 1\n",
        "                if counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                    break\n",
        "\n",
        "        # Load best model\n",
        "        model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error training model: {e}\")\n",
        "        raise\n",
        "\n",
        "# ==============================\n",
        "# ü§ñ AI Movie Chatbot System\n",
        "# ==============================\n",
        "class MovieChatbot:\n",
        "    def __init__(self):\n",
        "        self.responses = {\n",
        "            \"hello\": \"Hi there! üé¨ What movie are you in the mood for?\",\n",
        "            \"recommend\": \"Sure! I recommend watching Inception or Interstellar!\",\n",
        "            \"sad\": \"Feeling down? Try watching a feel-good movie like 'Forrest Gump'.\",\n",
        "            \"happy\": \"Great mood! How about a comedy like 'The Hangover'?\",\n",
        "            \"bye\": \"Goodbye! Hope you find the perfect movie! üçø\"\n",
        "        }\n",
        "\n",
        "    def chat(self, user_input):\n",
        "        try:\n",
        "            if user_input is None or not isinstance(user_input, str):\n",
        "                return \"I couldn't understand that. Could you please try again?\"\n",
        "\n",
        "            user_input = user_input.lower()\n",
        "            for key in self.responses.keys():\n",
        "                if key in user_input:\n",
        "                    return self.responses[key]\n",
        "            return \"Hmm... I'm not sure. How about watching 'The Dark Knight'? üé•\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error in chatbot response: {e}\")\n",
        "            return \"Sorry, I didn't understand that.\"\n",
        "\n",
        "# Initialize chatbot\n",
        "chatbot = MovieChatbot()\n",
        "\n",
        "# ==============================\n",
        "# üåê Web UI using Gradio\n",
        "# ==============================\n",
        "def ai_chat(user_input):\n",
        "    try:\n",
        "        return chatbot.chat(user_input)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Gradio chat function: {e}\")\n",
        "        return \"Sorry, an error occurred.\"\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Sentiment Analysis\n",
        "# ==============================\n",
        "def sentiment_analysis(text):\n",
        "    try:\n",
        "        if not text or not isinstance(text, str):\n",
        "            return {\"error\": \"Invalid text input\"}\n",
        "\n",
        "        nltk.download('vader_lexicon', quiet=True)\n",
        "        sia = SentimentIntensityAnalyzer()\n",
        "        return sia.polarity_scores(text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in sentiment analysis: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Word Cloud Generation\n",
        "# ==============================\n",
        "def generate_wordcloud(text):\n",
        "    try:\n",
        "        if not text or not isinstance(text, str):\n",
        "            print(\"Error: Invalid text for word cloud\")\n",
        "            return\n",
        "\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis(\"off\")\n",
        "        return plt\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating word cloud: {e}\")\n",
        "        return None\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Performance Monitoring\n",
        "# ==============================\n",
        "def monitor_performance():\n",
        "    try:\n",
        "        cpu_percent = psutil.cpu_percent()\n",
        "        memory_percent = psutil.virtual_memory().percent\n",
        "        return {\n",
        "            \"CPU Usage\": f\"{cpu_percent}%\",\n",
        "            \"Memory Usage\": f\"{memory_percent}%\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error monitoring performance: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Multimodal Chatbot Interface\n",
        "# ==============================\n",
        "def multimodal_chat(user_input):\n",
        "    try:\n",
        "        if not user_input or not isinstance(user_input, str):\n",
        "            return \"I couldn't understand that. Could you please try again?\"\n",
        "\n",
        "        # Process text input\n",
        "        response = chatbot.chat(user_input)\n",
        "\n",
        "        # Check for special commands\n",
        "        if \"sentiment\" in user_input.lower():\n",
        "            sentiment = sentiment_analysis(user_input)\n",
        "            return f\"{response}\\n\\nSentiment analysis: {sentiment}\"\n",
        "        elif \"performance\" in user_input.lower():\n",
        "            perf = monitor_performance()\n",
        "            return f\"{response}\\n\\nSystem performance: {perf}\"\n",
        "        else:\n",
        "            return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error in multimodal chat function: {e}\")\n",
        "        return \"Sorry, an error occurred.\"\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Natural Language Processing\n",
        "# ==============================\n",
        "def process_text(text):\n",
        "    try:\n",
        "        if not text or not isinstance(text, str):\n",
        "            return [\"Invalid input\"]\n",
        "\n",
        "        nltk.download('punkt', quiet=True)\n",
        "        tokens = word_tokenize(text)\n",
        "        return tokens\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return [\"Error: \" + str(e)]\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Time Series Forecasting\n",
        "# ==============================\n",
        "def forecast_ratings(ratings_data):\n",
        "    try:\n",
        "        if not ratings_data or not isinstance(ratings_data, dict):\n",
        "            return {\"error\": \"Invalid ratings data format\"}\n",
        "\n",
        "        # Ensure all required keys exist\n",
        "        required_keys = ['feature1', 'feature2', 'rating']\n",
        "        for key in required_keys:\n",
        "            if key not in ratings_data:\n",
        "                return {\"error\": f\"Missing key: {key}\"}\n",
        "\n",
        "        # Check if all values are lists of same length\n",
        "        lengths = [len(ratings_data[key]) for key in required_keys]\n",
        "        if len(set(lengths)) != 1:\n",
        "            return {\"error\": \"All data arrays must have the same length\"}\n",
        "\n",
        "        # Prepare data\n",
        "        df = pd.DataFrame(ratings_data)\n",
        "        X = df[['feature1', 'feature2']]\n",
        "        y = df['rating']\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train model\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "        # Evaluate model\n",
        "        mse = mean_squared_error(y_test, predictions)\n",
        "        return {\"mean_squared_error\": mse, \"predictions\": predictions.tolist()}\n",
        "    except Exception as e:\n",
        "        print(f\"Error forecasting ratings: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Recommendation System\n",
        "# ==============================\n",
        "def recommend_movies(user_preferences, movies):\n",
        "    try:\n",
        "        if not isinstance(user_preferences, list) or not isinstance(movies, list):\n",
        "            return {\"error\": \"Invalid input format\"}\n",
        "\n",
        "        # Validate movie data structure\n",
        "        for movie in movies:\n",
        "            if not isinstance(movie, dict) or 'title' not in movie or 'features' not in movie:\n",
        "                return {\"error\": \"Invalid movie data structure\"}\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        similarities = []\n",
        "        for movie in movies:\n",
        "            # Ensure dimensions match\n",
        "            if len(user_preferences) != len(movie['features']):\n",
        "                return {\"error\": \"Feature dimensions must match\"}\n",
        "\n",
        "            similarity = 1 - spatial.distance.cosine(user_preferences, movie['features'])\n",
        "            similarities.append((movie['title'], similarity))\n",
        "\n",
        "        # Sort movies by similarity\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return similarities[:5]\n",
        "    except Exception as e:\n",
        "        print(f\"Error recommending movies: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Clustering Analysis\n",
        "# ==============================\n",
        "def cluster_movies(movies_data):\n",
        "    try:\n",
        "        if not isinstance(movies_data, dict):\n",
        "            return {\"error\": \"Invalid movies data format\"}\n",
        "\n",
        "        # Ensure required features exist\n",
        "        required_features = ['feature1', 'feature2']\n",
        "        for feature in required_features:\n",
        "            if feature not in movies_data:\n",
        "                return {\"error\": f\"Missing feature: {feature}\"}\n",
        "\n",
        "        # Check if all features have the same length\n",
        "        lengths = [len(movies_data[feature]) for feature in required_features]\n",
        "        if len(set(lengths)) != 1:\n",
        "            return {\"error\": \"All feature arrays must have the same length\"}\n",
        "\n",
        "        # Prepare data\n",
        "        df = pd.DataFrame(movies_data)\n",
        "        X = df[required_features]\n",
        "\n",
        "        # Perform clustering\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        kmeans.fit(X)\n",
        "\n",
        "        # Predict cluster labels\n",
        "        labels = kmeans.predict(X)\n",
        "\n",
        "        return {\"clusters\": labels.tolist(), \"centers\": kmeans.cluster_centers_.tolist()}\n",
        "    except Exception as e:\n",
        "        print(f\"Error clustering movies: {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Web Scraping\n",
        "# ==============================\n",
        "def scrape_movie_info(movie_title):\n",
        "    try:\n",
        "        if not movie_title or not isinstance(movie_title, str):\n",
        "            return \"Invalid movie title\"\n",
        "\n",
        "        # Use a dummy response instead of actually scraping\n",
        "        # In a real application, you would use requests and BeautifulSoup\n",
        "        return f\"Movie information for: {movie_title} (This is a simulation - no actual scraping performed)\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping movie info: {e}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# ==============================\n",
        "# Additional Code for Part-of-Speech Tagging\n",
        "# ==============================\n",
        "def tag_parts_of_speech(text):\n",
        "    try:\n",
        "        if not text or not isinstance(text, str):\n",
        "            return [(\"Invalid\", \"input\")]\n",
        "\n",
        "        nltk.download('punkt', quiet=True)\n",
        "        nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "        tokens = word_tokenize(text)\n",
        "        return pos_tag(tokens)\n",
        "    except Exception as e:\n",
        "        print(f\"Error tagging parts of speech: {e}\")\n",
        "        return [(\"Error\", str(e))]\n",
        "\n",
        "# ==============================\n",
        "# üî• Main Execution\n",
        "# ==============================\n",
        "def main():\n",
        "    try:\n",
        "        print(\"üöÄ Starting AI-Powered Movie System...\")\n",
        "\n",
        "        # Initialize demo interface\n",
        "        demo = gr.Interface(\n",
        "            fn=multimodal_chat,\n",
        "            inputs=gr.Textbox(placeholder=\"Ask me about movies...\"),\n",
        "            outputs=\"text\",\n",
        "            title=\"üé¨ AI Movie Chatbot\",\n",
        "            description=\"Chat with me about movies, ask for recommendations, or get sentiment analysis!\"\n",
        "        )\n",
        "\n",
        "        # Skip actual model training in this example\n",
        "        # model = train_model()\n",
        "        print(\"üéÆ Movie AI system ready!\")\n",
        "\n",
        "        # Just return the demo without launching\n",
        "        return demo\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {e}\")\n",
        "        return None\n",
        "\n",
        "# ==============================\n",
        "# Example model usage (for demonstration)\n",
        "# ==============================\n",
        "def example_model_usage():\n",
        "    # Create a simple model for demonstration\n",
        "    model = MovieAI()\n",
        "\n",
        "    # Create sample input\n",
        "    sample_input = torch.tensor([[25, 8.5, 0.9]], dtype=torch.float32)\n",
        "\n",
        "    # Make a prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(sample_input)\n",
        "        prediction = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    print(f\"Sample prediction: {prediction} (1 = good movie, 0 = average movie)\")\n",
        "    return prediction\n",
        "\n",
        "# Run the main function if this script is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    demo = main()\n",
        "    # In a notebook or interactive environment, you would launch with:\n",
        "    # demo.launch()\n",
        "\n",
        "    # For demonstration only\n",
        "    example_prediction = example_model_usage()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cptM0BR9Fp_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3s6Q8IGIFBAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}